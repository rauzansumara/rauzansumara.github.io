<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta name="color-scheme" content="light dark">

    

    <meta name="author" content="Rauzan Sumara">
    <meta name="description" content="Here we are going to talk into the detail of how to improve Siamese Network Using Gabor Filter. I will also explain and give a comparison of Siamese Network without and with Gabor Filter seperately. Full code also can be obtained from my GitHub.
Siamese Network    In recent years, convolutional neural networks (CNNs) are almost good at every task, but these CNNs rely on more data to perform well.">
    <meta name="keywords" content="blog,data,analyst,scientist,statistician,personal">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Improving Siamese Network Using Gabor Filter"/>
<meta name="twitter:description" content="Here we are going to talk into the detail of how to improve Siamese Network Using Gabor Filter. I will also explain and give a comparison of Siamese Network without and with Gabor Filter seperately. Full code also can be obtained from my GitHub.
Siamese Network    In recent years, convolutional neural networks (CNNs) are almost good at every task, but these CNNs rely on more data to perform well."/>

    <meta property="og:title" content="Improving Siamese Network Using Gabor Filter" />
<meta property="og:description" content="Here we are going to talk into the detail of how to improve Siamese Network Using Gabor Filter. I will also explain and give a comparison of Siamese Network without and with Gabor Filter seperately. Full code also can be obtained from my GitHub.
Siamese Network    In recent years, convolutional neural networks (CNNs) are almost good at every task, but these CNNs rely on more data to perform well." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rauzansumara.github.io/post/improving-siamese-network-using-gabor-filter/" />
<meta property="article:published_time" content="2020-01-25T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-01-25T00:00:00+00:00" />


    <title>
  Improving Siamese Network Using Gabor Filter · RAUZAN SUMARA&#39;S WEBSITE
</title>

    
      <link rel="canonical" href="https://rauzansumara.github.io/post/improving-siamese-network-using-gabor-filter/">
    

    <link rel="preload" href="https://rauzansumara.github.io/fonts/forkawesome-webfont.woff2?v=1.1.7" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="https://rauzansumara.github.io/css/coder.min.eb7743f94930acfd17146aecc1f80e86fe35b3e451f2ec0c98485f9c4d962f34.css" integrity="sha256-63dD&#43;UkwrP0XFGrswfgOhv41s&#43;RR8uwMmEhfnE2WLzQ=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://rauzansumara.github.io/css/coder-dark.min.dde8a61eb31a32353b4baf3d9113f03c4ea2a8ca9bb736f59ca2d2b2cb664f0b.css" integrity="sha256-3eimHrMaMjU7S689kRPwPE6iqMqbtzb1nKLSsstmTws=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://rauzansumara.github.io/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://rauzansumara.github.io/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="https://rauzansumara.github.io/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="https://rauzansumara.github.io/images/apple-touch-icon.png">

    

    <meta name="generator" content="Hugo 0.80.0" />
  </head>

  
  
    
  
  <body class="preload-transitions colorscheme-auto"
        onload=""
  >
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://rauzansumara.github.io/">
      RAUZAN SUMARA&#39;S WEBSITE
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://rauzansumara.github.io/about/">About Me</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://rauzansumara.github.io/post/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://rauzansumara.github.io/projects/">Projects</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="https://rauzansumara.github.io/support/">How to Support</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1 class="title">
        <a class="title-link" href="https://rauzansumara.github.io/post/improving-siamese-network-using-gabor-filter/">
          Improving Siamese Network Using Gabor Filter
        </a>
      </h1>
    </header>

    <p>Here we are going to talk into the detail of how to improve Siamese Network Using Gabor Filter. I will also explain and give a comparison of Siamese Network without and with Gabor Filter seperately. Full code also can be obtained from my <a href="https://github.com/rauzansumara/siamese-network-with-gabor-filter"><strong>GitHub</strong></a>.</p>
<h2 id="siamese-network">
  Siamese Network
  <a class="heading-link" href="#siamese-network">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>In recent years, convolutional neural networks (CNNs) are almost good at every task, but these CNNs rely on more data to perform well. But for particular problems, we can’t always rely on getting more data, to solve this kind of tasks we have a new type of the CNN architecture called Siamese Networks. It uses only a few numbers of images to get better predictions. The ability to learn from very small data made Siamese networks more popular in nowadays.</p>
<p>Figure 1 : An architecture of Siamese Network</p>
<p><img src="https://raw.githubusercontent.com/rauzansumara/siamese-network-with-gabor-filter/master/images/Capture3.PNG" alt="An architecture of Siamese Network" title="An architecture of Siamese Network"></p>
<p><em>Source:</em> <a href="http://datahacker.rs/one-shot-learning-with-siamese-neural-network/">http://datahacker.rs</a></p>
<p>A Siamese Neural Network is a class of neural network architectures that contain two identical subnetworks. <strong>identical</strong> here means, they have the same configuration with the same parameters and weights. Parameter updating is mirrored across both sub-networks. It is used to find the similarity of the inputs by comparing its feature vectors, so these networks are used in many applications. Traditionally, a neural network learns to predict multiple classes. This poses a problem when we need to add/remove new classes to the data. In this case, we have to update the neural network and retrain it on the whole dataset. Also, deep neural networks need a large volume of data to train. On the other hand, Siamese Neural Network learns a similarity function. Thus, we can train it to see if the two images are the same (which we will do here). This enables us to classify new classes of data without training the network again.</p>
<h2 id="gabor-filter">
  Gabor Filter
  <a class="heading-link" href="#gabor-filter">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>A wide range of techniques have been developed to enhance the performance or ease the training of CNNs. <a href="https://www.semanticscholar.org/paper/Vision-based-Vehicle-Type-Classification-Using-Bank-Ji-Jin/a685814ef06de992889da4aefd87060624b538ad">Peijin Ji, Lianwen Jin, and X. Li (2007)</a> presented Vision-based Vehicle Type Classification Using Partial Gabor Filter Bank. The partial Gabor feature-based method can reduce the dimension and redundancy of the features and therefore much fewer memory and computation was involved. Experimental results showed that a partial Gabor filter bank outperforms the global Gabor filter bank in some situations. In addition, <a href="https://medium.com/@bairoukanasa5/improving-convolutional-neural-network-accuracy-using-gabor-filter-and-progressive-resizing-8e60caf50d8d">Anass Bairouk</a> and team designed and implemented several existing CNN models such as ResNet, AlexNet, VGG16, and InceptionV3 using Gabor filter. Based on accuracy, it has improvement that CNNs with Gabor Layers show better performance.</p>
<p>Figure 2 : Gabor filter Formula</p>
<p><img src="https://raw.githubusercontent.com/rauzansumara/siamese-network-with-gabor-filter/master/images/Capture1.PNG" alt="Gabor filter Formula" title="Gabor filter Formula"></p>
<p><em>Source:</em> <a href="">https://en.wikipedia.org/</a></p>
<p>Its impulse response is defined by a sinusoidal wave (a plane wave for 2D Gabor filters) multiplied by a Gaussian function. Because of the multiplication-convolution property (Convolution theorem), the Fourier transform of a Gabor filter&rsquo;s impulse response is the convolution of the Fourier transform of the harmonic function (sinusoidal function) and the Fourier transform of the Gaussian function. The filter has a real and an imaginary component representing orthogonal directions.The two components may be formed into a complex number. But in this case we are going to use <em>real filter</em> individually.</p>
<p>Gabor features are ideal for identifying the script of a word in a multilingual document, but Gabor filters have also been widely used in pattern analysis applications. The Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition. Relations between activations for a specific spatial location are very distinctive between objects in an image. Furthermore, important thing is to define hyperparamters <strong>Lambda, Theta, Psi, Sigma, and Gamma</strong>. Information about those hyperparamters has been explained well by <a href="http://matlabserver.cs.rug.nl/edgedetectionweb/web/edgedetection_params.html">N. Petkov and M.B. Wieling, University of Groningen</a></p>
<h2 id="code-python">
  Code Python
  <a class="heading-link" href="#code-python">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h2>
<p>In this article, we are going to implement Siamese Network with Gabor Filter in order to increase the accuracy. We will train the architecture to learn how to clasify handwritten digits on the MNIST dataset.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># import the necessary packages</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">io</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">cv2</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">numpy</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">np</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">tensorflow</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">tf</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">tensorflow_addons</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">tfa</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">tensorflow_datasets</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">tfds</span>
<span style="font-weight:bold">from</span> <span style="font-weight:bold">tensorflow.keras</span> <span style="font-weight:bold">import</span> optimizers, Model, backend
<span style="font-weight:bold">from</span> <span style="font-weight:bold">tensorflow.keras.layers</span> <span style="font-weight:bold">import</span> Dense, Conv2D, MaxPooling2D
<span style="font-weight:bold">from</span> <span style="font-weight:bold">tensorflow.keras.layers</span> <span style="font-weight:bold">import</span> Dropout, Flatten, Lambda, Input
<span style="font-weight:bold">from</span> <span style="font-weight:bold">sklearn.neighbors</span> <span style="font-weight:bold">import</span> KNeighborsClassifier
<span style="font-weight:bold">from</span> <span style="font-weight:bold">sklearn.preprocessing</span> <span style="font-weight:bold">import</span> MinMaxScaler
<span style="font-weight:bold">from</span> <span style="font-weight:bold">sklearn.metrics</span> <span style="font-weight:bold">import</span> accuracy_score, classification_report, confusion_matrix
<span style="font-weight:bold">import</span> <span style="font-weight:bold">matplotlib.pyplot</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">plt</span>
<span style="font-weight:bold">import</span> <span style="font-weight:bold">seaborn</span> <span style="font-weight:bold">as</span> <span style="font-weight:bold">sns</span>

</code></pre></div><h3 id="import-mnist-dataset">
  Import MNIST Dataset
  <a class="heading-link" href="#import-mnist-dataset">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># import dataset</span>
train_dataset, test_dataset = tfds.load(name=<span style="font-style:italic">&#34;mnist&#34;</span>, split=[<span style="font-style:italic">&#39;train&#39;</span>, <span style="font-style:italic">&#39;test&#39;</span>], as_supervised=True)

<span style="font-style:italic"># take labels of training and testing data</span>
y_train_labels = np.array([labels <span style="font-weight:bold">for</span> _, labels <span style="font-weight:bold">in</span> tfds.as_numpy(train_dataset)])
y_test_labels = np.array([labels <span style="font-weight:bold">for</span> _, labels <span style="font-weight:bold">in</span> tfds.as_numpy(test_dataset)])
</code></pre></div><div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># define soft max function</span>
<span style="font-weight:bold">def</span> softmax(x):
    <span style="font-style:italic">&#34;&#34;&#34;Compute softmax values for each sets of scores in x.&#34;&#34;&#34;</span>
    e_x = np.exp(x - np.max(x))
    <span style="font-weight:bold">return</span> e_x / e_x.sum()

<span style="font-style:italic"># normalize function (scale data between 0-1) </span>
<span style="font-weight:bold">def</span> _normalize_img(img, label):
    img = tf.cast(img, tf.float32) / 255.
    <span style="font-weight:bold">return</span> (img, label)

<span style="font-style:italic"># To generate pipeline of image pair on train dataset</span>
train_dataset = train_dataset.batch(32)
train_dataset = train_dataset.map(_normalize_img)

<span style="font-style:italic"># To generate pipeline of image pair on test dataset</span>
test_dataset = test_dataset.batch(32)
test_dataset = test_dataset.map(_normalize_img)
</code></pre></div><h3 id="generate-gabor-filter-banks">
  Generate Gabor Filter Banks
  <a class="heading-link" href="#generate-gabor-filter-banks">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Generate Gabor filter banks</span>
<span style="font-weight:bold">def</span> custom_gabor(shape, dtype=None):
    pi = np.pi
    real_kernels = []
    <span style="font-style:italic"># size, sigma, theta, lambda, gamma aspect ratio</span>
    <span style="font-weight:bold">for</span> theta <span style="font-weight:bold">in</span> np.array([0, pi/4, pi/2, pi*3/4, pi, pi*5/4, pi*3/2, 2*pi]):
        <span style="font-weight:bold">for</span> lamda <span style="font-weight:bold">in</span> (7, 11, 16, 22):
            <span style="font-weight:bold">for</span> psi <span style="font-weight:bold">in</span> (0, pi/2):
                real_kernel = cv2.getGaborKernel((5, 5), sigma=1.75, theta=theta, lambd=lamda, gamma=1, psi=psi)
                real_kernels.append(real_kernel)
    
    stacked_list = np.array([real_kernels])
    stacked_list = np.einsum(<span style="font-style:italic">&#39;hijk-&gt;jkhi&#39;</span>, stacked_list)
    stacked_list = backend.variable(stacked_list)
    random = backend.random_normal(shape, dtype=dtype)
    <span style="font-weight:bold">return</span> stacked_list
</code></pre></div><p>In this case, we are going to create 64 Gabor filters by combining hyperparameters <strong>Lambda, Theta, and Psi</strong>. While setting <strong>sigma=1.75</strong> as gaussian distribution and <strong>Gamma=1</strong> as circular of the spatial aspect ratio.</p>
<h3 id="siamese-network-model-1">
  Siamese Network (Model 1)
  <a class="heading-link" href="#siamese-network-model-1">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<p>Figure 3 : Siamese Network Model</p>
<p><img src="https://raw.githubusercontent.com/rauzansumara/siamese-network-with-gabor-filter/master/images/Capture2.PNG" alt="Siamese Network Model" title="Siamese Network Model"></p>
<p><em>Source:</em> <a href="">https://www.tensorflow.org/</a></p>
<p>Configuration of Siamese Network has been taken from <a href="https://www.tensorflow.org/addons/tutorials/losses_triplet">https://www.tensorflow.org/</a>, with some modificating the first layer by using <strong>64 filters.</strong></p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># define Siamese Network model</span>
<span style="font-weight:bold">def</span> Siamese_Network(input_Shape):

    <span style="font-style:italic"># specify the inputs for the feature extractor network</span>
    inputs = Input(input_Shape)

    <span style="font-style:italic"># define the first set of CONV =&gt; RELU =&gt; POOL =&gt; DROPOUT layers</span>
    x = Conv2D(filters=64, kernel_size=2, padding=<span style="font-style:italic">&#39;same&#39;</span>, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(inputs)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.3)(x)

    <span style="font-style:italic"># second set of CONV =&gt; RELU =&gt; POOL =&gt; DROPOUT layers =&gt; Flatten</span>
    x = Conv2D(filters=32, kernel_size=2, padding=<span style="font-style:italic">&#39;same&#39;</span>, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.3)(x)
    x = Flatten()(x)

    <span style="font-style:italic"># third set of Dense =&gt; Lambda</span>
    x = Dense(256, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(x)
    x = Lambda(<span style="font-weight:bold">lambda</span> x: tf.math.l2_normalize(x, axis=1))(x) <span style="font-style:italic"># L2 normalize embeddings</span>
    
    <span style="font-style:italic"># Output model</span>
    model = Model(inputs = inputs, outputs = x)
    <span style="font-weight:bold">return</span> model
</code></pre></div><h3 id="siamese-network-with-gabor-filter-model-2">
  Siamese Network with Gabor Filter (Model 2)
  <a class="heading-link" href="#siamese-network-with-gabor-filter-model-2">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># define Siamese Network with Gabor model</span>
<span style="font-weight:bold">def</span> Siamese_Network_Gabor(input_Shape):

    <span style="font-style:italic"># specify the inputs for the feature extractor network</span>
    inputs = Input(input_Shape)

    <span style="font-style:italic">#This layer is not trainable</span>
    x = Conv2D(filters=64, kernel_size=5, padding=<span style="font-style:italic">&#39;same&#39;</span>, kernel_initializer=custom_gabor, activation=<span style="font-style:italic">&#39;relu&#39;</span>, trainable=False)(inputs)
    
    <span style="font-style:italic"># define the first set of CONV =&gt; RELU =&gt; POOL =&gt; DROPOUT layer </span>
    x = Conv2D(filters=64, kernel_size=2, padding=<span style="font-style:italic">&#39;same&#39;</span>, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.3)(x)

    <span style="font-style:italic"># second set of CONV =&gt; RELU =&gt; POOL =&gt; DROPOUT layers =&gt; Flatten</span>
    x = Conv2D(filters=32, kernel_size=2, padding=<span style="font-style:italic">&#39;same&#39;</span>, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = Dropout(0.3)(x)
    x = Flatten()(x)

    <span style="font-style:italic"># third set of Dense =&gt; Lambda</span>
    x = Dense(256, activation=<span style="font-style:italic">&#39;relu&#39;</span>)(x)
    x = Lambda(<span style="font-weight:bold">lambda</span> x: tf.math.l2_normalize(x, axis=1))(x) <span style="font-style:italic"># L2 normalize embeddings</span>
    
    <span style="font-style:italic"># Output model</span>
    model = Model(inputs = inputs, outputs = x)
    <span style="font-weight:bold">return</span> model
</code></pre></div><h3 id="summary-of-the-models">
  Summary of the Models
  <a class="heading-link" href="#summary-of-the-models">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Shape of the MNIST dataset</span>
input_shape=(28,28,1)

<span style="font-style:italic"># Compile the Siamese Network model</span>
model1 = Siamese_Network(input_shape)
model1.compile(optimizer=optimizers.Adam(0.001),
              loss= tfa.losses.TripletHardLoss(soft=False))
model1.summary()
</code></pre></div><pre><code>Model: &quot;model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 28, 28, 64)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         
_________________________________________________________________
dropout (Dropout)            (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 32)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1568)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               401664    
_________________________________________________________________
lambda (Lambda)              (None, 256)               0         
=================================================================
Total params: 410,208
Trainable params: 410,208
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Compile the Siamese Network with Gabor model</span>
model2 = Siamese_Network_Gabor(input_shape)
model2.compile(optimizer=optimizers.Adam(0.001),
              loss= tfa.losses.TripletHardLoss(soft=False))
model2.summary()
</code></pre></div><pre><code>Model: &quot;model_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 28, 28, 64)        1664      
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 28, 28, 64)        16448     
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 14, 14, 32)        8224      
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 7, 7, 32)          0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1568)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               401664    
_________________________________________________________________
lambda_4 (Lambda)            (None, 256)               0         
=================================================================
Total params: 428,000
Trainable params: 426,336
Non-trainable params: 1,664
_________________________________________________________________
</code></pre>
<h3 id="training-model-1">
  Training Model 1
  <a class="heading-link" href="#training-model-1">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Train the model 1</span>
history1 = model1.fit(train_dataset.shuffle(1024), epochs=1)

<span style="font-style:italic"># Evaluate the model 1</span>
results_train = model1.predict(train_dataset)
results_test = model1.predict(test_dataset)

<span style="font-style:italic"># normalize data</span>
scaler = MinMaxScaler()
X_train = scaler.fit_transform(results_train)
X_test = scaler.fit_transform(results_test)

<span style="font-style:italic"># Apply kNN for classification k=11</span>
knn1 = KNeighborsClassifier(n_neighbors=11)
knn1.fit(X_train, y_train_labels)
y_test_pred1 = knn1.predict(X_test)

ACC_test1 = np.mean(y_test_pred1 == y_test_labels)
<span style="font-weight:bold">print</span>(f<span style="font-style:italic">&#34;ACC_test using Model 1 = {ACC_test1}&#34;</span>)

</code></pre></div><pre><code>1875/1875 [==============================] - 35s 18ms/step - loss: 0.8029
ACC_test using Model 1 = 0.9752
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Performance Evaluation of Model 1</span>
plt.figure(figsize=(10, 10))
cf_mat1 = confusion_matrix(y_test_pred1, y_test_labels)
sns.heatmap(cf_mat1, annot=True, fmt=<span style="font-style:italic">&#39;g&#39;</span>)
plt.show()
<span style="font-weight:bold">print</span>(classification_report(y_test_pred1, y_test_labels))
</code></pre></div><p><img src="https://rauzansumara.github.io/post/siamese-network-with-gabor-filter/output_22_0.svg" alt="svg"></p>
<pre><code>              precision    recall  f1-score   support

           0       0.99      0.98      0.98       995
           1       0.98      1.00      0.99      1113
           2       0.98      0.96      0.97      1054
           3       0.98      0.98      0.98      1012
           4       0.98      0.98      0.98       980
           5       0.98      0.97      0.98       903
           6       0.98      0.99      0.99       948
           7       0.95      0.98      0.97       995
           8       0.97      0.94      0.95      1007
           9       0.96      0.97      0.97       993

    accuracy                           0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000
</code></pre>
<h3 id="training-model-2">
  Training Model 2
  <a class="heading-link" href="#training-model-2">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Train the model 2</span>
history2 = model2.fit(train_dataset.shuffle(1024), epochs=1)

<span style="font-style:italic"># Evaluate the model 2</span>
results_train = model2.predict(train_dataset)
results_test = model2.predict(test_dataset)

<span style="font-style:italic"># normalize data</span>
scaler = MinMaxScaler()
X_train = scaler.fit_transform(results_train)
X_test = scaler.fit_transform(results_test)

<span style="font-style:italic"># Apply kNN for classification k=11</span>
knn2 = KNeighborsClassifier(n_neighbors=11)
knn2.fit(X_train, y_train_labels)
y_test_pred2 = knn2.predict(X_test)

ACC_test2 = np.mean(y_test_pred2 == y_test_labels)
<span style="font-weight:bold">print</span>(f<span style="font-style:italic">&#34;ACC_test using Model 2 = {ACC_test2}&#34;</span>)
</code></pre></div><pre><code>1875/1875 [==============================] - 57s 30ms/step - loss: 0.2296
ACC_test using Model 2 = 0.985
</code></pre>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="font-style:italic"># Performance Evaluation of Model 2</span>
plt.figure(figsize=(10, 10))
cf_mat2 = confusion_matrix(y_test_pred2, y_test_labels)
sns.heatmap(cf_mat2, annot=True, fmt=<span style="font-style:italic">&#39;g&#39;</span>)
plt.show()
<span style="font-weight:bold">print</span>(classification_report(y_test_pred2, y_test_labels))
</code></pre></div><p><img src="https://rauzansumara.github.io/post/siamese-network-with-gabor-filter/output_25_0.svg" alt="svg"></p>
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.99      0.99       987
           1       0.99      0.99      0.99      1143
           2       0.99      0.99      0.99      1034
           3       0.99      0.99      0.99      1009
           4       0.99      0.99      0.99       977
           5       0.99      0.98      0.99       902
           6       0.99      1.00      0.99       947
           7       0.98      0.99      0.98      1023
           8       0.98      0.95      0.96       999
           9       0.96      0.99      0.98       979

    accuracy                           0.98     10000
   macro avg       0.98      0.99      0.98     10000
weighted avg       0.99      0.98      0.98     10000
</code></pre>
<p>Here we are going to compare Siamese Network without and with Gabor Filter. k-nearest neighbors algorithm will be used as final classifier based on <strong>k = 11</strong>. According to accuracy of test data, we got <strong>0.9752</strong> using Siamese Network without Gabor Filter and <strong>0.985</strong> using Siamese Network with Gabor Filter. As we can see that accuracy increases after combining Siamese Network with Gabor Filter. Something that we need to keep in mind while implementing Gabor Filter, we have to have some basic knowledge about its hyperparamters <strong>Lambda, Theta, Psi, Sigma, and Gamma</strong>. Because good result will depend on how we set the hyperparamters.</p>

  </article>
</section>

  

      </div>

      
  <footer class="footer">
    <section class="container">
      
        <p>Use data to reveal the future</p>
      
      
        ©
        
        2021
         Rauzan Sumara 
      
      
      
        
      
    </section>
  </footer>


    </main>

    
      
      <script src="https://rauzansumara.github.io/js/coder.min.f92783b4545b68f3523e5d6ad91d93f76818f9d0db2ffa13bda31b6119cde62b.js" integrity="sha256-&#43;SeDtFRbaPNSPl1q2R2T92gY&#43;dDbL/oTvaMbYRnN5is="></script>
    

    

    

    <script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '//analytics.example.com/tracker.js', 'fathom');
fathom('set', 'siteId', 'ABCDE');
fathom('trackPageview');
</script>


    

    

    

    

    
  </body>

</html>
